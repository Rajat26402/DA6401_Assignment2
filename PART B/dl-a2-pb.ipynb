{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11438164,"sourceType":"datasetVersion","datasetId":7164837}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.cuda.amp import autocast\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, random_split\nfrom torch.amp import autocast, GradScaler\nimport wandb\n\nwandb.login(key=\"d6f8c99f1fd73267470842bbf00f03ae845f7308\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T11:22:04.653603Z","iopub.execute_input":"2025-04-18T11:22:04.654164Z","iopub.status.idle":"2025-04-18T11:22:20.573376Z","shell.execute_reply.started":"2025-04-18T11:22:04.654135Z","shell.execute_reply":"2025-04-18T11:22:20.572791Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mda24m014\u001b[0m (\u001b[33mda24m014-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndata_dir = \"/kaggle/input/nature/nature_12K/inaturalist_12K\"\nbatch_size = 64\nimg_size = 224\nnum_classes = 10\nepochs = 10\nlr = 1e-4\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T11:22:24.472097Z","iopub.execute_input":"2025-04-18T11:22:24.472738Z","iopub.status.idle":"2025-04-18T11:22:24.560919Z","shell.execute_reply.started":"2025-04-18T11:22:24.472711Z","shell.execute_reply":"2025-04-18T11:22:24.560020Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize((img_size, img_size)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ToTensor()\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((img_size, img_size)),\n    transforms.ToTensor()\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T11:22:25.433958Z","iopub.execute_input":"2025-04-18T11:22:25.434502Z","iopub.status.idle":"2025-04-18T11:22:25.438767Z","shell.execute_reply.started":"2025-04-18T11:22:25.434465Z","shell.execute_reply":"2025-04-18T11:22:25.438107Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"full_dataset = datasets.ImageFolder(os.path.join(data_dir, \"train\"), transform=train_transform)\ntrain_size = int(0.8 * len(full_dataset))\nval_size = len(full_dataset) - train_size\ntrain_ds, val_ds = random_split(full_dataset, [train_size, val_size])\ntest_ds = datasets.ImageFolder(os.path.join(data_dir, \"val\"), transform=val_transform)\n\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_ds, batch_size=batch_size, num_workers=2)\ntest_loader = DataLoader(test_ds, batch_size=batch_size, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T11:22:26.981487Z","iopub.execute_input":"2025-04-18T11:22:26.981746Z","iopub.status.idle":"2025-04-18T11:22:47.419496Z","shell.execute_reply.started":"2025-04-18T11:22:26.981727Z","shell.execute_reply":"2025-04-18T11:22:47.418931Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\nfor param in model.features.parameters():\n    param.requires_grad = False  # Freeze convolutional layers\n\n# Replace classifier head\nmodel.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T11:22:49.929347Z","iopub.execute_input":"2025-04-18T11:22:49.930008Z","iopub.status.idle":"2025-04-18T11:22:54.733353Z","shell.execute_reply.started":"2025-04-18T11:22:49.929986Z","shell.execute_reply":"2025-04-18T11:22:54.732736Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n100%|██████████| 528M/528M [00:02<00:00, 199MB/s] \n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\nscaler = GradScaler()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T11:22:55.995943Z","iopub.execute_input":"2025-04-18T11:22:55.996556Z","iopub.status.idle":"2025-04-18T11:22:56.000710Z","shell.execute_reply.started":"2025-04-18T11:22:55.996531Z","shell.execute_reply":"2025-04-18T11:22:56.000139Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"wandb.init(project=\"DLA2-PartB\", name=\"VGG16-finetune\", config={\n    \"strategy\": \"freeze features, fine-tune classifier\",\n    \"model\": \"VGG16\",\n    \"epochs\": epochs,\n    \"batch_size\": batch_size,\n    \"lr\": lr\n})\nwandb.watch(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T11:22:57.630615Z","iopub.execute_input":"2025-04-18T11:22:57.631377Z","iopub.status.idle":"2025-04-18T11:23:05.033499Z","shell.execute_reply.started":"2025-04-18T11:22:57.631351Z","shell.execute_reply":"2025-04-18T11:23:05.032942Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_112257-a39madzx</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m014-iit-madras/DLA2-PartB/runs/a39madzx' target=\"_blank\">VGG16-finetune</a></strong> to <a href='https://wandb.ai/da24m014-iit-madras/DLA2-PartB' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m014-iit-madras/DLA2-PartB' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA2-PartB</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m014-iit-madras/DLA2-PartB/runs/a39madzx' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA2-PartB/runs/a39madzx</a>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"def train_one_epoch(loader):\n    model.train()\n    total_loss, correct = 0, 0\n    for inputs, labels in loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n\n        # Use autocast with device_type set to 'cuda' (for GPU) or 'cpu' (for CPU)\n        with autocast(device_type=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item() * inputs.size(0)\n        correct += (outputs.argmax(1) == labels).sum().item()\n\n    return total_loss / len(loader.dataset), correct / len(loader.dataset)\n\n\n\ndef evaluate(loader):\n    model.eval()\n    total_loss, correct = 0, 0\n    with torch.no_grad():\n        for inputs, labels in loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            # Use autocast with device_type set to 'cuda' (for GPU) or 'cpu' (for CPU)\n            with autocast(device_type=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n            \n            total_loss += loss.item() * inputs.size(0)\n            correct += (outputs.argmax(1) == labels).sum().item()\n    \n    return total_loss / len(loader.dataset), correct / len(loader.dataset)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T11:23:08.221620Z","iopub.execute_input":"2025-04-18T11:23:08.221902Z","iopub.status.idle":"2025-04-18T11:23:08.229815Z","shell.execute_reply.started":"2025-04-18T11:23:08.221878Z","shell.execute_reply":"2025-04-18T11:23:08.229141Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"for epoch in range(epochs):\n    train_loss, train_acc = train_one_epoch(train_loader)\n    val_loss, val_acc = evaluate(val_loader)\n    print(f\"[Epoch {epoch+1}] Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n    wandb.log({\n        \"epoch\": epoch+1,\n        \"train_loss\": train_loss,\n        \"train_acc\": train_acc,\n        \"val_loss\": val_loss,\n        \"val_acc\": val_acc\n    })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T11:23:10.532022Z","iopub.execute_input":"2025-04-18T11:23:10.532649Z","iopub.status.idle":"2025-04-18T11:35:16.512924Z","shell.execute_reply.started":"2025-04-18T11:23:10.532618Z","shell.execute_reply":"2025-04-18T11:35:16.512121Z"}},"outputs":[{"name":"stdout","text":"[Epoch 1] Train Acc: 0.4928 | Val Acc: 0.5675\n[Epoch 2] Train Acc: 0.6067 | Val Acc: 0.6100\n[Epoch 3] Train Acc: 0.6667 | Val Acc: 0.6170\n[Epoch 4] Train Acc: 0.6962 | Val Acc: 0.6320\n[Epoch 5] Train Acc: 0.7281 | Val Acc: 0.6360\n[Epoch 6] Train Acc: 0.7565 | Val Acc: 0.6360\n[Epoch 7] Train Acc: 0.7903 | Val Acc: 0.6415\n[Epoch 8] Train Acc: 0.8066 | Val Acc: 0.6340\n[Epoch 9] Train Acc: 0.8286 | Val Acc: 0.6210\n[Epoch 10] Train Acc: 0.8435 | Val Acc: 0.6380\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"torch.save(model.state_dict(), \"vgg16_finetuned.pth\")\nwandb.save(\"vgg16_finetuned.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T11:35:46.554938Z","iopub.execute_input":"2025-04-18T11:35:46.556365Z","iopub.status.idle":"2025-04-18T11:35:47.608875Z","shell.execute_reply.started":"2025-04-18T11:35:46.556334Z","shell.execute_reply":"2025-04-18T11:35:47.608296Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"['/kaggle/working/wandb/run-20250418_112257-a39madzx/files/vgg16_finetuned.pth']"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"**RESNET**","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.amp import autocast, GradScaler\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, random_split\nimport wandb\n\nwandb.login(key=\"d6f8c99f1fd73267470842bbf00f03ae845f7308\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:54:34.763549Z","iopub.execute_input":"2025-04-18T13:54:34.763720Z","iopub.status.idle":"2025-04-18T13:54:52.149161Z","shell.execute_reply.started":"2025-04-18T13:54:34.763703Z","shell.execute_reply":"2025-04-18T13:54:52.148584Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mda24m014\u001b[0m (\u001b[33mda24m014-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndata_dir = \"/kaggle/input/nature/nature_12K/inaturalist_12K\"\nbatch_size = 64\nimg_size = 224\nnum_classes = 10\nepochs = 10\nlr = 1e-4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:54:54.557972Z","iopub.execute_input":"2025-04-18T13:54:54.558218Z","iopub.status.idle":"2025-04-18T13:54:54.651744Z","shell.execute_reply.started":"2025-04-18T13:54:54.558201Z","shell.execute_reply":"2025-04-18T13:54:54.651020Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize((img_size, img_size)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ToTensor()\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((img_size, img_size)),\n    transforms.ToTensor()\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:54:56.252873Z","iopub.execute_input":"2025-04-18T13:54:56.253151Z","iopub.status.idle":"2025-04-18T13:54:56.258004Z","shell.execute_reply.started":"2025-04-18T13:54:56.253131Z","shell.execute_reply":"2025-04-18T13:54:56.257155Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"full_dataset = datasets.ImageFolder(os.path.join(data_dir, \"train\"), transform=train_transform)\ntrain_size = int(0.8 * len(full_dataset))\nval_size = len(full_dataset) - train_size\ntrain_ds, val_ds = random_split(full_dataset, [train_size, val_size])\ntest_ds = datasets.ImageFolder(os.path.join(data_dir, \"val\"), transform=val_transform)\n\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_ds, batch_size=batch_size, num_workers=2)\ntest_loader = DataLoader(test_ds, batch_size=batch_size, num_workers=2)\n\n# Load pre-trained ResNet50\nmodel = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:54:57.851016Z","iopub.execute_input":"2025-04-18T13:54:57.851281Z","iopub.status.idle":"2025-04-18T13:55:11.635570Z","shell.execute_reply.started":"2025-04-18T13:54:57.851262Z","shell.execute_reply":"2025-04-18T13:55:11.634791Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 210MB/s]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"for param in model.parameters():\n    param.requires_grad = False\n\n# Replace the final fully connected layer\nmodel.fc = nn.Linear(model.fc.in_features, num_classes)\n\n# Unfreeze only the new fc layer\nfor param in model.fc.parameters():\n    param.requires_grad = True\n\nmodel = model.to(device)\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\nscaler = GradScaler()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:55:50.478381Z","iopub.execute_input":"2025-04-18T13:55:50.478643Z","iopub.status.idle":"2025-04-18T13:55:50.488096Z","shell.execute_reply.started":"2025-04-18T13:55:50.478624Z","shell.execute_reply":"2025-04-18T13:55:50.487332Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"wandb.init(project=\"DLA2-PartB\", name=\"ResNet50-finetune\", config={\n    \"strategy\": \"freeze all except final fc layer\",\n    \"model\": \"ResNet50\",\n    \"epochs\": epochs,\n    \"batch_size\": batch_size,\n    \"lr\": lr\n})\nwandb.watch(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:01:08.040568Z","iopub.execute_input":"2025-04-18T14:01:08.041116Z","iopub.status.idle":"2025-04-18T14:01:15.514381Z","shell.execute_reply.started":"2025-04-18T14:01:08.041092Z","shell.execute_reply":"2025-04-18T14:01:15.513554Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_140108-zbaztvkj</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m014-iit-madras/DLA2-PartB/runs/zbaztvkj' target=\"_blank\">ResNet50-finetune</a></strong> to <a href='https://wandb.ai/da24m014-iit-madras/DLA2-PartB' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m014-iit-madras/DLA2-PartB' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA2-PartB</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m014-iit-madras/DLA2-PartB/runs/zbaztvkj' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA2-PartB/runs/zbaztvkj</a>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"def train_one_epoch(loader):\n    model.train()\n    total_loss, correct = 0, 0\n    for inputs, labels in loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        with autocast(device_type=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        total_loss += loss.item() * inputs.size(0)\n        correct += (outputs.argmax(1) == labels).sum().item()\n    return total_loss / len(loader.dataset), correct / len(loader.dataset)\n\ndef evaluate(loader):\n    model.eval()\n    total_loss, correct = 0, 0\n    with torch.no_grad():\n        for inputs, labels in loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            with autocast(device_type=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n            total_loss += loss.item() * inputs.size(0)\n            correct += (outputs.argmax(1) == labels).sum().item()\n    return total_loss / len(loader.dataset), correct / len(loader.dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:01:20.133199Z","iopub.execute_input":"2025-04-18T14:01:20.133939Z","iopub.status.idle":"2025-04-18T14:01:20.141590Z","shell.execute_reply.started":"2025-04-18T14:01:20.133912Z","shell.execute_reply":"2025-04-18T14:01:20.140863Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"for epoch in range(epochs):\n    train_loss, train_acc = train_one_epoch(train_loader)\n    val_loss, val_acc = evaluate(val_loader)\n    print(f\"[Epoch {epoch+1}] Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n    wandb.log({\n        \"epoch\": epoch+1,\n        \"train_loss\": train_loss,\n        \"train_acc\": train_acc,\n        \"val_loss\": val_loss,\n        \"val_acc\": val_acc\n    })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:01:22.264591Z","iopub.execute_input":"2025-04-18T14:01:22.265313Z","iopub.status.idle":"2025-04-18T14:12:06.113559Z","shell.execute_reply.started":"2025-04-18T14:01:22.265287Z","shell.execute_reply":"2025-04-18T14:12:06.112834Z"}},"outputs":[{"name":"stdout","text":"[Epoch 1] Train Acc: 0.6111 | Val Acc: 0.6330\n[Epoch 2] Train Acc: 0.6537 | Val Acc: 0.6515\n[Epoch 3] Train Acc: 0.6712 | Val Acc: 0.6605\n[Epoch 4] Train Acc: 0.6868 | Val Acc: 0.6635\n[Epoch 5] Train Acc: 0.6970 | Val Acc: 0.6750\n[Epoch 6] Train Acc: 0.6967 | Val Acc: 0.6800\n[Epoch 7] Train Acc: 0.7066 | Val Acc: 0.6920\n[Epoch 8] Train Acc: 0.7086 | Val Acc: 0.6955\n[Epoch 9] Train Acc: 0.7146 | Val Acc: 0.6960\n[Epoch 10] Train Acc: 0.7087 | Val Acc: 0.6940\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"torch.save(model.state_dict(), \"resnet50_finetuned.pth\")\nwandb.save(\"resnet50_finetuned.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:13:11.116223Z","iopub.execute_input":"2025-04-18T14:13:11.117172Z","iopub.status.idle":"2025-04-18T14:13:11.277486Z","shell.execute_reply.started":"2025-04-18T14:13:11.117144Z","shell.execute_reply":"2025-04-18T14:13:11.276944Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"['/kaggle/working/wandb/run-20250418_140108-zbaztvkj/files/resnet50_finetuned.pth']"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"RESNET-2","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import datasets, transforms, models\nfrom torch.amp import autocast, GradScaler\nimport wandb\n\nwandb.login(key=\"d6f8c99f1fd73267470842bbf00f03ae845f7308\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:50:20.052551Z","iopub.execute_input":"2025-04-18T15:50:20.052734Z","iopub.status.idle":"2025-04-18T15:50:40.870270Z","shell.execute_reply.started":"2025-04-18T15:50:20.052717Z","shell.execute_reply":"2025-04-18T15:50:40.869678Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mda24m014\u001b[0m (\u001b[33mda24m014-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndata_dir = \"/kaggle/input/nature/nature_12K/inaturalist_12K\"\nbatch_size = 64\nimg_size = 224\nnum_classes = 10\nepochs = 10\nlr = 1e-4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:50:44.032563Z","iopub.execute_input":"2025-04-18T15:50:44.032832Z","iopub.status.idle":"2025-04-18T15:50:44.121300Z","shell.execute_reply.started":"2025-04-18T15:50:44.032809Z","shell.execute_reply":"2025-04-18T15:50:44.120576Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize((img_size, img_size)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ToTensor()\n])\nval_transform = transforms.Compose([\n    transforms.Resize((img_size, img_size)),\n    transforms.ToTensor()\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:50:45.414009Z","iopub.execute_input":"2025-04-18T15:50:45.414704Z","iopub.status.idle":"2025-04-18T15:50:45.418700Z","shell.execute_reply.started":"2025-04-18T15:50:45.414675Z","shell.execute_reply":"2025-04-18T15:50:45.418179Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"full_dataset = datasets.ImageFolder(os.path.join(data_dir, \"train\"), transform=train_transform)\ntrain_size = int(0.8 * len(full_dataset))\nval_size = len(full_dataset) - train_size\ntrain_ds, val_ds = random_split(full_dataset, [train_size, val_size])\ntest_ds = datasets.ImageFolder(os.path.join(data_dir, \"val\"), transform=val_transform)\n\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_ds, batch_size=batch_size, num_workers=2)\ntest_loader = DataLoader(test_ds, batch_size=batch_size, num_workers=2)\n\nmodel = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:50:46.534611Z","iopub.execute_input":"2025-04-18T15:50:46.535346Z","iopub.status.idle":"2025-04-18T15:51:02.249118Z","shell.execute_reply.started":"2025-04-18T15:50:46.535320Z","shell.execute_reply":"2025-04-18T15:51:02.248359Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 173MB/s] \n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"for param in model.parameters():\n    param.requires_grad = False\n\n# Unfreeze last ResNet block (layer4) and fc\nfor param in model.layer4.parameters():\n    param.requires_grad = True\nfor param in model.fc.parameters():\n    param.requires_grad = True\n\n# Replace the final classification layer\nmodel.fc = nn.Linear(model.fc.in_features, num_classes)\nmodel = model.to(device)\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\nscaler = GradScaler()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:53:12.580900Z","iopub.execute_input":"2025-04-18T15:53:12.581760Z","iopub.status.idle":"2025-04-18T15:53:12.846939Z","shell.execute_reply.started":"2025-04-18T15:53:12.581730Z","shell.execute_reply":"2025-04-18T15:53:12.846174Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"wandb.init(project=\"DLA2-PartB\", name=\"ResNet50-finetune-layer4+fc\", config={\n    \"strategy\": \"unfreeze layer4 and fc\",\n    \"model\": \"ResNet50\",\n    \"epochs\": epochs,\n    \"batch_size\": batch_size,\n    \"lr\": lr\n})\nwandb.watch(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:53:15.102264Z","iopub.execute_input":"2025-04-18T15:53:15.102981Z","iopub.status.idle":"2025-04-18T15:53:23.624593Z","shell.execute_reply.started":"2025-04-18T15:53:15.102956Z","shell.execute_reply":"2025-04-18T15:53:23.624027Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_155315-2g6sexu5</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m014-iit-madras/DLA2-PartB/runs/2g6sexu5' target=\"_blank\">ResNet50-finetune-layer4+fc</a></strong> to <a href='https://wandb.ai/da24m014-iit-madras/DLA2-PartB' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m014-iit-madras/DLA2-PartB' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA2-PartB</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m014-iit-madras/DLA2-PartB/runs/2g6sexu5' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA2-PartB/runs/2g6sexu5</a>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"def train_one_epoch(loader):\n    model.train()\n    total_loss, correct = 0, 0\n    for inputs, labels in loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        with autocast(device_type=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        total_loss += loss.item() * inputs.size(0)\n        correct += (outputs.argmax(1) == labels).sum().item()\n\n    return total_loss / len(loader.dataset), correct / len(loader.dataset)\n\n# Evaluation\ndef evaluate(loader):\n    model.eval()\n    total_loss, correct = 0, 0\n    with torch.no_grad():\n        for inputs, labels in loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            with autocast(device_type=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n            total_loss += loss.item() * inputs.size(0)\n            correct += (outputs.argmax(1) == labels).sum().item()\n    return total_loss / len(loader.dataset), correct / len(loader.dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:53:23.858001Z","iopub.execute_input":"2025-04-18T15:53:23.858619Z","iopub.status.idle":"2025-04-18T15:53:23.866699Z","shell.execute_reply.started":"2025-04-18T15:53:23.858591Z","shell.execute_reply":"2025-04-18T15:53:23.866029Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"for epoch in range(epochs):\n    train_loss, train_acc = train_one_epoch(train_loader)\n    val_loss, val_acc = evaluate(val_loader)\n    print(f\"[Epoch {epoch+1}] Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n    wandb.log({\n        \"epoch\": epoch+1,\n        \"train_loss\": train_loss,\n        \"train_acc\": train_acc,\n        \"val_loss\": val_loss,\n        \"val_acc\": val_acc\n    })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:54:29.684755Z","iopub.execute_input":"2025-04-18T15:54:29.685380Z","iopub.status.idle":"2025-04-18T16:06:45.770627Z","shell.execute_reply.started":"2025-04-18T15:54:29.685354Z","shell.execute_reply":"2025-04-18T16:06:45.769856Z"}},"outputs":[{"name":"stdout","text":"[Epoch 1] Train Acc: 0.6776 | Val Acc: 0.7415\n[Epoch 2] Train Acc: 0.8155 | Val Acc: 0.7570\n[Epoch 3] Train Acc: 0.8684 | Val Acc: 0.7645\n[Epoch 4] Train Acc: 0.9082 | Val Acc: 0.7815\n[Epoch 5] Train Acc: 0.9312 | Val Acc: 0.7735\n[Epoch 6] Train Acc: 0.9485 | Val Acc: 0.7670\n[Epoch 7] Train Acc: 0.9575 | Val Acc: 0.7700\n[Epoch 8] Train Acc: 0.9660 | Val Acc: 0.7730\n[Epoch 9] Train Acc: 0.9730 | Val Acc: 0.7790\n[Epoch 10] Train Acc: 0.9767 | Val Acc: 0.7720\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"torch.save(model.state_dict(), \"resnet50_finetuned_layer4_fc.pth\")\nwandb.save(\"resnet50_finetuned_layer4_fc.pth\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"RESNET-3","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.amp import autocast\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, random_split\nfrom torch.amp import GradScaler\nimport wandb\n\nwandb.login(key=\"d6f8c99f1fd73267470842bbf00f03ae845f7308\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T16:35:14.034215Z","iopub.execute_input":"2025-04-18T16:35:14.034459Z","iopub.status.idle":"2025-04-18T16:35:30.765776Z","shell.execute_reply.started":"2025-04-18T16:35:14.034434Z","shell.execute_reply":"2025-04-18T16:35:30.765194Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mda24m014\u001b[0m (\u001b[33mda24m014-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndata_dir = \"/kaggle/input/nature/nature_12K/inaturalist_12K\"\nbatch_size = 64\nimg_size = 224\nnum_classes = 10\nepochs = 10\nlr = 1e-4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T16:35:45.586389Z","iopub.execute_input":"2025-04-18T16:35:45.587241Z","iopub.status.idle":"2025-04-18T16:35:45.682992Z","shell.execute_reply.started":"2025-04-18T16:35:45.587203Z","shell.execute_reply":"2025-04-18T16:35:45.682218Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize((img_size + 32, img_size + 32)),\n    transforms.RandomCrop(img_size),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1)),\n    transforms.ToTensor()\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((img_size, img_size)),\n    transforms.ToTensor()\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T16:35:47.025794Z","iopub.execute_input":"2025-04-18T16:35:47.026068Z","iopub.status.idle":"2025-04-18T16:35:47.031329Z","shell.execute_reply.started":"2025-04-18T16:35:47.026046Z","shell.execute_reply":"2025-04-18T16:35:47.030523Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"full_dataset = datasets.ImageFolder(os.path.join(data_dir, \"train\"), transform=train_transform)\ntrain_size = int(0.8 * len(full_dataset))\nval_size = len(full_dataset) - train_size\ntrain_ds, val_ds = random_split(full_dataset, [train_size, val_size])\ntest_ds = datasets.ImageFolder(os.path.join(data_dir, \"val\"), transform=val_transform)\n\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_ds, batch_size=batch_size, num_workers=2)\ntest_loader = DataLoader(test_ds, batch_size=batch_size, num_workers=2)\n\n# Load pre-trained ResNet50\nmodel = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T16:35:48.457484Z","iopub.execute_input":"2025-04-18T16:35:48.458108Z","iopub.status.idle":"2025-04-18T16:36:01.760932Z","shell.execute_reply.started":"2025-04-18T16:35:48.458089Z","shell.execute_reply":"2025-04-18T16:36:01.760423Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 221MB/s]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"for param in model.parameters():\n    param.requires_grad = False\nfor param in model.layer4.parameters():\n    param.requires_grad = True\nfor param in model.fc.parameters():\n    param.requires_grad = True\n\n# Modify classifier for 10-class classification\nmodel.fc = nn.Linear(model.fc.in_features, num_classes)\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\nscaler = GradScaler()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T16:36:13.687222Z","iopub.execute_input":"2025-04-18T16:36:13.687916Z","iopub.status.idle":"2025-04-18T16:36:13.928486Z","shell.execute_reply.started":"2025-04-18T16:36:13.687889Z","shell.execute_reply":"2025-04-18T16:36:13.927909Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"wandb.init(project=\"DLA2-PartB\", name=\"ResNet50-finetune-augmented\", config={\n    \"strategy\": \"unfreeze layer4 and fc\",\n    \"model\": \"ResNet50\",\n    \"epochs\": epochs,\n    \"batch_size\": batch_size,\n    \"lr\": lr,\n    \"augmentation\": True\n})\nwandb.watch(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T16:36:15.942978Z","iopub.execute_input":"2025-04-18T16:36:15.943347Z","iopub.status.idle":"2025-04-18T16:36:23.452029Z","shell.execute_reply.started":"2025-04-18T16:36:15.943326Z","shell.execute_reply":"2025-04-18T16:36:23.451502Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_163616-rkunqgf5</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m014-iit-madras/DLA2-PartB/runs/rkunqgf5' target=\"_blank\">ResNet50-finetune-augmented</a></strong> to <a href='https://wandb.ai/da24m014-iit-madras/DLA2-PartB' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m014-iit-madras/DLA2-PartB' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA2-PartB</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m014-iit-madras/DLA2-PartB/runs/rkunqgf5' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA2-PartB/runs/rkunqgf5</a>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"def train_one_epoch(loader):\n    model.train()\n    total_loss, correct = 0, 0\n    for inputs, labels in loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        with autocast(device_type=\"cuda\"):\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        total_loss += loss.item() * inputs.size(0)\n        correct += (outputs.argmax(1) == labels).sum().item()\n\n    return total_loss / len(loader.dataset), correct / len(loader.dataset)\n\ndef evaluate(loader):\n    model.eval()\n    total_loss, correct = 0, 0\n    with torch.no_grad():\n        for inputs, labels in loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            with autocast(device_type=\"cuda\"):\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n            total_loss += loss.item() * inputs.size(0)\n            correct += (outputs.argmax(1) == labels).sum().item()\n\n    return total_loss / len(loader.dataset), correct / len(loader.dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T16:36:26.318834Z","iopub.execute_input":"2025-04-18T16:36:26.319202Z","iopub.status.idle":"2025-04-18T16:36:26.326769Z","shell.execute_reply.started":"2025-04-18T16:36:26.319140Z","shell.execute_reply":"2025-04-18T16:36:26.326051Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def test(loader):\n    model.eval()\n    correct = 0\n    with torch.no_grad():\n        for inputs, labels in loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            correct += (outputs.argmax(1) == labels).sum().item()\n    return correct / len(loader.dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T16:36:30.161006Z","iopub.execute_input":"2025-04-18T16:36:30.161317Z","iopub.status.idle":"2025-04-18T16:36:30.166873Z","shell.execute_reply.started":"2025-04-18T16:36:30.161293Z","shell.execute_reply":"2025-04-18T16:36:30.166356Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"for epoch in range(epochs):\n    train_loss, train_acc = train_one_epoch(train_loader)\n    val_loss, val_acc = evaluate(val_loader)\n    print(f\"[Epoch {epoch+1}] Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n    wandb.log({\n        \"epoch\": epoch+1,\n        \"train_loss\": train_loss,\n        \"train_acc\": train_acc,\n        \"val_loss\": val_loss,\n        \"val_acc\": val_acc\n    })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T16:36:32.001554Z","iopub.execute_input":"2025-04-18T16:36:32.001821Z","iopub.status.idle":"2025-04-18T16:52:07.205818Z","shell.execute_reply.started":"2025-04-18T16:36:32.001801Z","shell.execute_reply":"2025-04-18T16:52:07.205084Z"}},"outputs":[{"name":"stdout","text":"[Epoch 1] Train Acc: 0.6133 | Val Acc: 0.7080\n[Epoch 2] Train Acc: 0.7283 | Val Acc: 0.7185\n[Epoch 3] Train Acc: 0.7726 | Val Acc: 0.7295\n[Epoch 4] Train Acc: 0.7898 | Val Acc: 0.7370\n[Epoch 5] Train Acc: 0.8106 | Val Acc: 0.7375\n[Epoch 6] Train Acc: 0.8337 | Val Acc: 0.7480\n[Epoch 7] Train Acc: 0.8454 | Val Acc: 0.7545\n[Epoch 8] Train Acc: 0.8670 | Val Acc: 0.7600\n[Epoch 9] Train Acc: 0.8789 | Val Acc: 0.7460\n[Epoch 10] Train Acc: 0.8886 | Val Acc: 0.7345\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"test_acc = test(test_loader)\nprint(f\"Test Accuracy: {test_acc:.4f}\")\nwandb.log({\"test_acc\": test_acc})\n\ntorch.save(model.state_dict(), \"resnet50_finetuned.pth\")\nwandb.save(\"resnet50_finetuned.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T16:54:04.538295Z","iopub.execute_input":"2025-04-18T16:54:04.539591Z","iopub.status.idle":"2025-04-18T16:54:27.757518Z","shell.execute_reply.started":"2025-04-18T16:54:04.539563Z","shell.execute_reply":"2025-04-18T16:54:27.756897Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 0.7615\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"['/kaggle/working/wandb/run-20250418_163616-rkunqgf5/files/resnet50_finetuned.pth']"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}